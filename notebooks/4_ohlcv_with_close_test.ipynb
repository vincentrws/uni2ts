{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# OHLCV Scaler with Close Included in OHLC Collective Normalization\n",
                "\n",
                "This notebook tests including Close in the OHLC collective z-score normalization.\n",
                "The idea is to normalize Open, High, Low, and Close together as a group."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step0",
            "metadata": {},
            "source": [
                "## Step 0: Setup and Data Preparation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "setup",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ All dependencies imported successfully\n",
                        "\n",
                        "Features shape: torch.Size([10, 7])\n",
                        "Features:\n",
                        "tensor([[1.0000e+02, 1.0500e+02, 9.9000e+01, 1.0200e+02, 1.0000e+06, 0.0000e+00,\n",
                        "         0.0000e+00],\n",
                        "        [1.0400e+02, 1.0800e+02, 1.0300e+02, 1.0600e+02, 1.2000e+06, 5.0000e+00,\n",
                        "         0.0000e+00],\n",
                        "        [1.0700e+02, 1.1000e+02, 1.0600e+02, 1.0900e+02, 9.0000e+05, 1.0000e+01,\n",
                        "         0.0000e+00],\n",
                        "        [1.0900e+02, 1.1200e+02, 1.0800e+02, 1.1100e+02, 1.1000e+06, 1.5000e+01,\n",
                        "         0.0000e+00],\n",
                        "        [1.1100e+02, 1.1400e+02, 1.1000e+02, 1.1300e+02, 9.5000e+05, 2.0000e+01,\n",
                        "         0.0000e+00],\n",
                        "        [1.1300e+02, 1.1600e+02, 1.1200e+02, 1.1500e+02, 1.0500e+06, 2.5000e+01,\n",
                        "         1.0000e+00],\n",
                        "        [1.1500e+02, 1.1800e+02, 1.1400e+02, 1.1700e+02, 1.1500e+06, 3.0000e+01,\n",
                        "         1.0000e+00],\n",
                        "        [1.1700e+02, 1.2000e+02, 1.1600e+02, 1.1900e+02, 1.2500e+06, 3.5000e+01,\n",
                        "         1.0000e+00],\n",
                        "        [1.1900e+02, 1.2200e+02, 1.1800e+02, 1.2100e+02, 1.3500e+06, 4.0000e+01,\n",
                        "         1.0000e+00],\n",
                        "        [1.2100e+02, 1.2400e+02, 1.2000e+02, 1.2300e+02, 1.4500e+06, 4.5000e+01,\n",
                        "         1.0000e+00]])\n",
                        "\n",
                        "Packed target shape: torch.Size([70, 1])\n",
                        "Variate ID shape: torch.Size([70])\n",
                        "Unique variate IDs: [0, 1, 2, 3, 4, 5, 6]\n",
                        "\n",
                        "✓ Data prepared successfully\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "from einops import rearrange, repeat, reduce\n",
                "from uni2ts.common.torch_util import safe_div\n",
                "\n",
                "# Set seed for reproducibility\n",
                "torch.manual_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "print(\"✓ All dependencies imported successfully\")\n",
                "\n",
                "# Create sample OHLCV data with Close included\n",
                "# Format: [open, high, low, close, volume, minutes_since_open, day_of_week]\n",
                "time_steps = 10\n",
                "num_variates = 7  # [open, high, low, close, volume, minutes_since_open, day_of_week]\n",
                "patch_size = 1\n",
                "\n",
                "# Generate realistic OHLCV data\n",
                "open_data = torch.tensor([100.0, 104.0, 107.0, 109.0, 111.0, 113.0, 115.0, 117.0, 119.0, 121.0])\n",
                "high_data = torch.tensor([105.0, 108.0, 110.0, 112.0, 114.0, 116.0, 118.0, 120.0, 122.0, 124.0])\n",
                "low_data = torch.tensor([99.0, 103.0, 106.0, 108.0, 110.0, 112.0, 114.0, 116.0, 118.0, 120.0])\n",
                "close_data = torch.tensor([102.0, 106.0, 109.0, 111.0, 113.0, 115.0, 117.0, 119.0, 121.0, 123.0])\n",
                "volume_data = torch.tensor([1000000, 1200000, 900000, 1100000, 950000, 1050000, 1150000, 1250000, 1350000, 1450000], dtype=torch.float32)\n",
                "minutes_data = torch.tensor([0.0, 5.0, 10.0, 15.0, 20.0, 25.0, 30.0, 35.0, 40.0, 45.0])\n",
                "dow_data = torch.tensor([0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
                "\n",
                "# Combine all features [time, dim]\n",
                "# Format: [open, high, low, close, volume, minutes_since_open, day_of_week]\n",
                "features = torch.stack([open_data, high_data, low_data, close_data, volume_data, minutes_data, dow_data], dim=1)\n",
                "print(f\"\\nFeatures shape: {features.shape}\")\n",
                "print(f\"Features:\\n{features}\")\n",
                "\n",
                "# Add patch dimension [time, dim, patch]\n",
                "features = features.unsqueeze(-1)\n",
                "\n",
                "# Reshape to packed format: [time, dim, patch] -> [(dim * time), patch]\n",
                "target_packed = rearrange(features, \"t d p -> (d t) p\")\n",
                "print(f\"\\nPacked target shape: {target_packed.shape}\")\n",
                "\n",
                "# Create sample_id (all same sample)\n",
                "sample_id = torch.ones(target_packed.shape[0], dtype=torch.long)\n",
                "\n",
                "# Create variate_id\n",
                "variate_id = repeat(torch.arange(num_variates), \"d -> (d t)\", t=time_steps)\n",
                "print(f\"Variate ID shape: {variate_id.shape}\")\n",
                "print(f\"Unique variate IDs: {torch.unique(variate_id).tolist()}\")\n",
                "\n",
                "# All observed\n",
                "observed_mask = torch.ones_like(target_packed, dtype=torch.bool)\n",
                "\n",
                "print(f\"\\n✓ Data prepared successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step1",
            "metadata": {},
            "source": [
                "## Step 1: Create Group Mapping for OHLC Collective Normalization\n",
                "\n",
                "Map variates to groups:\n",
                "- OHLC (0,1,2,3) → group 0 (collective)\n",
                "- Volume (4) → group 1 (individual)\n",
                "- Others (5,6) → individual groups"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "step1_group_mapping",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "======================================================================\n",
                        "STEP 1: Create Group Mapping for OHLC Collective Normalization\n",
                        "======================================================================\n",
                        "\n",
                        "Group mapping created:\n",
                        "  OHLC mask count: 40\n",
                        "  Volume mask count: 10\n",
                        "  Other mask count: 20\n",
                        "\n",
                        "Group ID distribution:\n",
                        "  Group 0: 40 positions\n",
                        "  Group 1: 10 positions\n",
                        "  Group 7: 10 positions\n",
                        "  Group 8: 10 positions\n",
                        "\n",
                        "✓ Group mapping created successfully\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"STEP 1: Create Group Mapping for OHLC Collective Normalization\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Create group mapping\n",
                "group_id = torch.zeros_like(variate_id, dtype=torch.long)\n",
                "\n",
                "# Define indices\n",
                "open_idx, high_idx, low_idx, close_idx = 0, 1, 2, 3\n",
                "volume_idx = 4\n",
                "minutes_idx, dow_idx = 5, 6\n",
                "\n",
                "# Create masks\n",
                "ohlc_mask = torch.isin(variate_id, torch.tensor([open_idx, high_idx, low_idx, close_idx]))\n",
                "volume_mask = (variate_id == volume_idx)\n",
                "other_mask = ~(ohlc_mask | volume_mask)\n",
                "\n",
                "# Assign group IDs\n",
                "group_id[ohlc_mask] = 0  # OHLC group\n",
                "group_id[volume_mask] = 1  # Volume group\n",
                "group_id[other_mask] = variate_id[other_mask] + 2  # Individual groups for others\n",
                "\n",
                "print(f\"\\nGroup mapping created:\")\n",
                "print(f\"  OHLC mask count: {ohlc_mask.sum().item()}\")\n",
                "print(f\"  Volume mask count: {volume_mask.sum().item()}\")\n",
                "print(f\"  Other mask count: {other_mask.sum().item()}\")\n",
                "\n",
                "print(f\"\\nGroup ID distribution:\")\n",
                "for g_id in torch.unique(group_id):\n",
                "    count = (group_id == g_id).sum().item()\n",
                "    print(f\"  Group {g_id}: {count} positions\")\n",
                "\n",
                "print(f\"\\n✓ Group mapping created successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step2",
            "metadata": {},
            "source": [
                "## Step 2: Create Identity Mask for Sample and Group"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "step2_identity_mask",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "======================================================================\n",
                        "STEP 2: Create Identity Mask\n",
                        "======================================================================\n",
                        "\n",
                        "Identity mask shape: torch.Size([70, 70])\n",
                        "Identity mask dtype: torch.bool\n",
                        "\n",
                        "Identity mask statistics:\n",
                        "  Total True values: 1900\n",
                        "  Total positions: 4900\n",
                        "\n",
                        "✓ Identity mask created successfully\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"STEP 2: Create Identity Mask\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Create identity mask for sample and group\n",
                "id_mask = torch.logical_and(\n",
                "    torch.eq(sample_id.unsqueeze(-1), sample_id.unsqueeze(-2)),\n",
                "    torch.eq(group_id.unsqueeze(-1), group_id.unsqueeze(-2)),\n",
                ")\n",
                "\n",
                "print(f\"\\nIdentity mask shape: {id_mask.shape}\")\n",
                "print(f\"Identity mask dtype: {id_mask.dtype}\")\n",
                "\n",
                "# Count True values per group\n",
                "print(f\"\\nIdentity mask statistics:\")\n",
                "print(f\"  Total True values: {id_mask.sum().item()}\")\n",
                "print(f\"  Total positions: {id_mask.shape[0] * id_mask.shape[1]}\")\n",
                "\n",
                "print(f\"\\n✓ Identity mask created successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step3",
            "metadata": {},
            "source": [
                "## Step 3: Compute Total Observations per Group"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "step3_total_obs",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "======================================================================\n",
                        "STEP 3: Compute Total Observations per Group\n",
                        "======================================================================\n",
                        "\n",
                        "Total observations shape: torch.Size([70, 1])\n",
                        "Total observations dtype: torch.int64\n",
                        "\n",
                        "Unique observation counts: [10, 40]\n",
                        "\n",
                        "Observation count distribution:\n",
                        "  10 observations: 30 positions\n",
                        "  40 observations: 40 positions\n",
                        "\n",
                        "✓ Total observations computed successfully\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"STEP 3: Compute Total Observations per Group\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Compute total observations per group using einops.reduce\n",
                "tobs = reduce(\n",
                "    id_mask * reduce(observed_mask, \"... seq dim -> ... 1 seq\", \"sum\"),\n",
                "    \"... seq1 seq2 -> ... seq1 1\",\n",
                "    \"sum\",\n",
                ")\n",
                "\n",
                "print(f\"\\nTotal observations shape: {tobs.shape}\")\n",
                "print(f\"Total observations dtype: {tobs.dtype}\")\n",
                "\n",
                "# Show unique values\n",
                "unique_tobs = torch.unique(tobs)\n",
                "print(f\"\\nUnique observation counts: {unique_tobs.tolist()}\")\n",
                "\n",
                "# Show distribution\n",
                "print(f\"\\nObservation count distribution:\")\n",
                "for count in unique_tobs:\n",
                "    num_positions = (tobs == count).sum().item()\n",
                "    print(f\"  {count.item()} observations: {num_positions} positions\")\n",
                "\n",
                "print(f\"\\n✓ Total observations computed successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step4",
            "metadata": {},
            "source": [
                "## Step 4: Compute Group-wise Mean (Location Parameter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "step4_group_mean",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "======================================================================\n",
                        "STEP 4: Compute Group-wise Mean\n",
                        "======================================================================\n",
                        "\n",
                        "Group-wise mean shape: torch.Size([70, 1])\n",
                        "Group-wise mean dtype: torch.float32\n",
                        "\n",
                        "Unique mean values: [0.5, 22.5, 112.67500305175781, 1140000.0]\n",
                        "\n",
                        "Mean statistics:\n",
                        "  Min: 0.500000\n",
                        "  Max: 1140000.000000\n",
                        "  Mean: 162924.781250\n",
                        "\n",
                        "Means per group:\n",
                        "  Group 0: [112.67500305175781]\n",
                        "  Group 1: [1140000.0]\n",
                        "  Group 7: [22.5]\n",
                        "  Group 8: [0.5]\n",
                        "\n",
                        "✓ Group-wise mean computed successfully\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"STEP 4: Compute Group-wise Mean\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Compute group-wise mean using einops.reduce\n",
                "loc_grouped = reduce(\n",
                "    id_mask * reduce(target_packed * observed_mask, \"... seq dim -> ... 1 seq\", \"sum\"),\n",
                "    \"... seq1 seq2 -> ... seq1 1\",\n",
                "    \"sum\",\n",
                ")\n",
                "loc_grouped = safe_div(loc_grouped, tobs)\n",
                "\n",
                "print(f\"\\nGroup-wise mean shape: {loc_grouped.shape}\")\n",
                "print(f\"Group-wise mean dtype: {loc_grouped.dtype}\")\n",
                "\n",
                "# Show unique values\n",
                "unique_means = torch.unique(loc_grouped)\n",
                "print(f\"\\nUnique mean values: {unique_means.tolist()}\")\n",
                "\n",
                "# Show statistics\n",
                "print(f\"\\nMean statistics:\")\n",
                "print(f\"  Min: {loc_grouped.min().item():.6f}\")\n",
                "print(f\"  Max: {loc_grouped.max().item():.6f}\")\n",
                "print(f\"  Mean: {loc_grouped.mean().item():.6f}\")\n",
                "\n",
                "# Show per-group means\n",
                "print(f\"\\nMeans per group:\")\n",
                "for g_id in torch.unique(group_id):\n",
                "    mask = (group_id == g_id)\n",
                "    group_means = loc_grouped[mask]\n",
                "    unique_group_means = torch.unique(group_means)\n",
                "    print(f\"  Group {g_id}: {unique_group_means.tolist()}\")\n",
                "\n",
                "print(f\"\\n✓ Group-wise mean computed successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step5",
            "metadata": {},
            "source": [
                "## Step 5: Compute Group-wise Standard Deviation (Scale Parameter)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "step5_group_std",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "======================================================================\n",
                        "STEP 5: Compute Group-wise Standard Deviation\n",
                        "======================================================================\n",
                        "\n",
                        "Group-wise std shape: torch.Size([70, 1])\n",
                        "Group-wise std dtype: torch.float32\n",
                        "\n",
                        "Unique std values: [0.5270557999610901, 6.564815521240234, 15.138252258300781, 176068.171875]\n",
                        "\n",
                        "Std statistics:\n",
                        "  Min: 0.527056\n",
                        "  Max: 176068.171875\n",
                        "  Mean: 25158.582031\n",
                        "\n",
                        "Stds per group:\n",
                        "  Group 0: [6.564815521240234]\n",
                        "  Group 1: [176068.171875]\n",
                        "  Group 7: [15.138252258300781]\n",
                        "  Group 8: [0.5270557999610901]\n",
                        "\n",
                        "✓ Group-wise std computed successfully\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"STEP 5: Compute Group-wise Standard Deviation\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Compute group-wise variance using einops.reduce\n",
                "var_grouped = reduce(\n",
                "    id_mask\n",
                "    * reduce(\n",
                "        ((target_packed - loc_grouped) ** 2) * observed_mask,\n",
                "        \"... seq dim -> ... 1 seq\",\n",
                "        \"sum\",\n",
                "    ),\n",
                "    \"... seq1 seq2 -> ... seq1 1\",\n",
                "    \"sum\",\n",
                ")\n",
                "var_grouped = safe_div(var_grouped, (tobs - 1))  # Bessel's correction\n",
                "scale_grouped = torch.sqrt(var_grouped + 1e-5)  # Add minimum_scale\n",
                "\n",
                "print(f\"\\nGroup-wise std shape: {scale_grouped.shape}\")\n",
                "print(f\"Group-wise std dtype: {scale_grouped.dtype}\")\n",
                "\n",
                "# Show unique values\n",
                "unique_stds = torch.unique(scale_grouped)\n",
                "print(f\"\\nUnique std values: {unique_stds.tolist()}\")\n",
                "\n",
                "# Show statistics\n",
                "print(f\"\\nStd statistics:\")\n",
                "print(f\"  Min: {scale_grouped.min().item():.6f}\")\n",
                "print(f\"  Max: {scale_grouped.max().item():.6f}\")\n",
                "print(f\"  Mean: {scale_grouped.mean().item():.6f}\")\n",
                "\n",
                "# Show per-group stds\n",
                "print(f\"\\nStds per group:\")\n",
                "for g_id in torch.unique(group_id):\n",
                "    mask = (group_id == g_id)\n",
                "    group_stds = scale_grouped[mask]\n",
                "    unique_group_stds = torch.unique(group_stds)\n",
                "    print(f\"  Group {g_id}: {unique_group_stds.tolist()}\")\n",
                "\n",
                "print(f\"\\n✓ Group-wise std computed successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step6",
            "metadata": {},
            "source": [
                "## Step 6: Apply Group-wise Statistics to All Positions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "step6_apply_stats",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "======================================================================\n",
                        "STEP 6: Apply Group-wise Statistics to All Positions\n",
                        "======================================================================\n",
                        "\n",
                        "Initialized loc shape: torch.Size([70, 1])\n",
                        "Initialized scale shape: torch.Size([70, 1])\n",
                        "\n",
                        "Applied group-wise statistics to all positions\n",
                        "\n",
                        "Statistics per variate:\n",
                        "\n",
                        "  Variate 0:\n",
                        "    Unique loc values: [112.67500305175781]\n",
                        "    Unique scale values: [6.564815521240234]\n",
                        "\n",
                        "  Variate 1:\n",
                        "    Unique loc values: [112.67500305175781]\n",
                        "    Unique scale values: [6.564815521240234]\n",
                        "\n",
                        "  Variate 2:\n",
                        "    Unique loc values: [112.67500305175781]\n",
                        "    Unique scale values: [6.564815521240234]\n",
                        "\n",
                        "  Variate 3:\n",
                        "    Unique loc values: [112.67500305175781]\n",
                        "    Unique scale values: [6.564815521240234]\n",
                        "\n",
                        "  Variate 4:\n",
                        "    Unique loc values: [1140000.0]\n",
                        "    Unique scale values: [176068.171875]\n",
                        "\n",
                        "  Variate 5:\n",
                        "    Unique loc values: [22.5]\n",
                        "    Unique scale values: [15.138252258300781]\n",
                        "\n",
                        "  Variate 6:\n",
                        "    Unique loc values: [0.5]\n",
                        "    Unique scale values: [0.5270557999610901]\n",
                        "\n",
                        "✓ Group-wise statistics applied successfully\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"STEP 6: Apply Group-wise Statistics to All Positions\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Initialize loc and scale tensors\n",
                "loc = torch.zeros_like(target_packed, dtype=target_packed.dtype)\n",
                "scale = torch.ones_like(target_packed, dtype=target_packed.dtype)\n",
                "\n",
                "print(f\"\\nInitialized loc shape: {loc.shape}\")\n",
                "print(f\"Initialized scale shape: {scale.shape}\")\n",
                "\n",
                "# For each position, find its group and apply the corresponding statistics\n",
                "for i in range(target_packed.shape[0]):\n",
                "    s_id = sample_id[i]\n",
                "    g_id = group_id[i]\n",
                "    \n",
                "    # Find the group statistics for this sample and group\n",
                "    mask = torch.logical_and(\n",
                "        torch.eq(sample_id, s_id),\n",
                "        torch.eq(group_id, g_id),\n",
                "    )\n",
                "    \n",
                "    if mask.any():\n",
                "        # Get the first position with this sample and group\n",
                "        idx = mask.nonzero(as_tuple=True)[0][0]\n",
                "        loc[i] = loc_grouped[idx]\n",
                "        scale[i] = scale_grouped[idx]\n",
                "\n",
                "print(f\"\\nApplied group-wise statistics to all positions\")\n",
                "\n",
                "# Show statistics per variate\n",
                "print(f\"\\nStatistics per variate:\")\n",
                "for v_id in torch.unique(variate_id):\n",
                "    mask = (variate_id == v_id)\n",
                "    var_locs = loc[mask]\n",
                "    var_scales = scale[mask]\n",
                "    \n",
                "    unique_loc = torch.unique(var_locs)\n",
                "    unique_scale = torch.unique(var_scales)\n",
                "    \n",
                "    print(f\"\\n  Variate {v_id}:\")\n",
                "    print(f\"    Unique loc values: {unique_loc.tolist()}\")\n",
                "    print(f\"    Unique scale values: {unique_scale.tolist()}\")\n",
                "\n",
                "print(f\"\\n✓ Group-wise statistics applied successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step7",
            "metadata": {},
            "source": [
                "## Step 7: Apply Mid-Range Normalization for Time Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "step7_midrange",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "======================================================================\n",
                        "STEP 7: Apply Mid-Range Normalization for Time Features\n",
                        "======================================================================\n",
                        "\n",
                        "Applied minutes_since_open normalization:\n",
                        "  Positions: 10\n",
                        "  Mid: 195.0\n",
                        "  Range: 97.5\n",
                        "\n",
                        "Applied day_of_week normalization:\n",
                        "  Positions: 10\n",
                        "  Mid: 2.0\n",
                        "  Range: 1.0\n",
                        "\n",
                        "Verification:\n",
                        "  Minutes loc: [195.0]\n",
                        "  Minutes scale: [97.5]\n",
                        "  Day of week loc: [2.0]\n",
                        "  Day of week scale: [1.0]\n",
                        "\n",
                        "✓ Mid-range normalization applied successfully\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"STEP 7: Apply Mid-Range Normalization for Time Features\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "# Define mid-range parameters\n",
                "minutes_mid = 195.0\n",
                "minutes_range = 97.5\n",
                "dow_mid = 2.0\n",
                "dow_range = 1.0\n",
                "\n",
                "# Apply minutes_since_open normalization\n",
                "minutes_mask = (variate_id == minutes_idx)\n",
                "if minutes_mask.any():\n",
                "    loc[minutes_mask] = minutes_mid\n",
                "    scale[minutes_mask] = minutes_range\n",
                "    print(f\"\\nApplied minutes_since_open normalization:\")\n",
                "    print(f\"  Positions: {minutes_mask.sum().item()}\")\n",
                "    print(f\"  Mid: {minutes_mid}\")\n",
                "    print(f\"  Range: {minutes_range}\")\n",
                "\n",
                "# Apply day_of_week normalization\n",
                "dow_mask = (variate_id == dow_idx)\n",
                "if dow_mask.any():\n",
                "    loc[dow_mask] = dow_mid\n",
                "    scale[dow_mask] = dow_range\n",
                "    print(f\"\\nApplied day_of_week normalization:\")\n",
                "    print(f\"  Positions: {dow_mask.sum().item()}\")\n",
                "    print(f\"  Mid: {dow_mid}\")\n",
                "    print(f\"  Range: {dow_range}\")\n",
                "\n",
                "# Verify time features\n",
                "print(f\"\\nVerification:\")\n",
                "minutes_loc_unique = torch.unique(loc[minutes_mask])\n",
                "minutes_scale_unique = torch.unique(scale[minutes_mask])\n",
                "print(f\"  Minutes loc: {minutes_loc_unique.tolist()}\")\n",
                "print(f\"  Minutes scale: {minutes_scale_unique.tolist()}\")\n",
                "\n",
                "dow_loc_unique = torch.unique(loc[dow_mask])\n",
                "dow_scale_unique = torch.unique(scale[dow_mask])\n",
                "print(f\"  Day of week loc: {dow_loc_unique.tolist()}\")\n",
                "print(f\"  Day of week scale: {dow_scale_unique.tolist()}\")\n",
                "\n",
                "print(f\"\\n✓ Mid-range normalization applied successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "step8",
            "metadata": {},
            "source": [
                "## Step 8: Verify OHLC Collective Normalization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "step8_verify_ohlc",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "======================================================================\n",
                        "STEP 8: Verify OHLC Collective Normalization\n",
                        "======================================================================\n",
                        "\n",
                        "Verification of OHLC Collective Normalization:\n",
                        "  Open loc: [112.67500305175781]\n",
                        "  High loc: [112.67500305175781]\n",
                        "  Low loc: [112.67500305175781]\n",
                        "  Close loc: [112.67500305175781]\n",
                        "  ✓ OHLC collective normalization verified!\n",
                        "\n",
                        "Verification of Volume Individual Normalization:\n",
                        "  Volume loc: [1140000.0]\n",
                        "  ✓ Volume individual normalization verified!\n",
                        "\n",
                        "✓ All verifications passed!\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n\" + \"=\"*70)\n",
                "print(\"STEP 8: Verify OHLC Collective Normalization\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "print(f\"\\nVerification of OHLC Collective Normalization:\")\n",
                "open_loc = torch.unique(loc[variate_id == open_idx])\n",
                "high_loc = torch.unique(loc[variate_id == high_idx])\n",
                "low_loc = torch.unique(loc[variate_id == low_idx])\n",
                "close_loc = torch.unique(loc[variate_id == close_idx])\n",
                "\n",
                "print(f\"  Open loc: {open_loc.tolist()}\")\n",
                "print(f\"  High loc: {high_loc.tolist()}\")\n",
                "print(f\"  Low loc: {low_loc.tolist()}\")\n",
                "print(f\"  Close loc: {close_loc.tolist()}\")\n",
                "\n",
                "# Verify they all have the same value\n",
                "assert len(open_loc) == 1 and len(high_loc) == 1 and len(low_loc) == 1 and len(close_loc) == 1, \"OHLC should have single loc value\"\n",
                "assert torch.isclose(open_loc[0], high_loc[0], atol=1e-4), \"Open and High should have same loc\"\n",
                "assert torch.isclose(open_loc[0], low_loc[0], atol=1e-4), \"Open and Low should have same loc\"\n",
                "assert torch.isclose(open_loc[0], close_loc[0], atol=1e-4), \"Open and Close should have same loc\"\n",
                "print(f\"  ✓ OHLC collective normalization verified!\")\n",
                "\n",
                "# Verify Volume is different\n",
                "print(f\"\\nVerification of Volume Individual Normalization:\")\n",
                "volume_loc = torch.unique(loc[variate_id == volume_idx])\n",
                "print(f\"  Volume loc: {volume_loc.tolist()}\")\n",
                "assert not torch.isclose(volume_loc[0], open_loc[0], atol=1e-4), \"Volume should differ from OHLC\"\n",
                "print(f\"  ✓ Volume individual normalization verified!\")\n",
                "\n",
                "print(f\"\\n✓ All verifications passed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "summary",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "Successfully implemented OHLC collective normalization with Close included:\n",
                "\n",
                "✓ Open, High, Low, Close share the same mean and std (Group 0)\n",
                "✓ Volume has individual mean and std (Group 1)\n",
                "✓ Time features use fixed mid-range values\n",
                "✓ All operations are vectorized using einops.reduce"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
